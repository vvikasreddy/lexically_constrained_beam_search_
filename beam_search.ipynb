{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvikasreddy/lexically_constrained_beam_search_/blob/main/beam_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## downloading essential modules"
      ],
      "metadata": {
        "id": "4FVX-zdj1zoV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTeRXGcN1aLG",
        "outputId": "a9970081-5557-4703-8b99-8b6f16dad697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the cs-en translation"
      ],
      "metadata": {
        "id": "xFty4zD45HPX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "BsIWSdWT1nXy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"wmt/wmt16\", \"tr-en\")"
      ],
      "metadata": {
        "id": "wh8kntBaDQkQ",
        "outputId": "2af41b9d-9be2-455d-af04-acc2a2793756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZmmV6aM18Zm",
        "outputId": "91e363d7-d6bd-400d-a6de-5b86e1c13a95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 205756\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1001\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VskMyKZb7W3U",
        "outputId": "17841eda-e9cf-46a9-f1c6-9d5263b9afd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'translation': {'en': \"Kosovo's privatisation process is under scrutiny\",\n",
              "  'tr': \"Kosova'nın özelleştirme süreci büyüteç altında\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-tr-en\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-tr-en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-D25X8-3fDH",
        "outputId": "382fae56-4b07-4164-d5ff-483292439ed7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N_fTjkeRDq17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDq8hERj4pMq",
        "outputId": "4c2f5a09-8f03-4485-b8c6-f56970c75bd9",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MarianMTModel(\n",
              "  (model): MarianModel(\n",
              "    (shared): Embedding(62389, 512, padding_idx=62388)\n",
              "    (encoder): MarianEncoder(\n",
              "      (embed_tokens): Embedding(62389, 512, padding_idx=62388)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLU()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): MarianDecoder(\n",
              "      (embed_tokens): Embedding(62389, 512, padding_idx=62388)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLU()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=62389, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-9TiGYzPIwj4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/docs/transformers/model_doc/marian"
      ],
      "metadata": {
        "id": "MklXmhpQ8zMq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_translation(src_text, max_length = 50):\n",
        "\n",
        "  # Tokenize input\n",
        "  encoder_inputs = tokenizer(src_text, return_tensors=\"pt\")\n",
        "\n",
        "  # intializes the decoder input with decoder start token\n",
        "  decoder_input = torch.tensor([[model.config.decoder_start_token_id]])\n",
        "\n",
        "  # change the model to eval mode.\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    generated_tokens = []\n",
        "\n",
        "    while len(generated_tokens) < max_length:\n",
        "\n",
        "      outputs = model(\n",
        "          input_ids=encoder_inputs.input_ids,\n",
        "          attention_mask=encoder_inputs.attention_mask,\n",
        "          decoder_input_ids=decoder_input\n",
        "      )\n",
        "\n",
        "\n",
        "      next_token_logits = outputs.logits[:, -1, :]\n",
        "\n",
        "\n",
        "      # get the token with maximum logits value\n",
        "      next_token = torch.argmax(next_token_logits, dim=-1)\n",
        "\n",
        "      generated_tokens.append(next_token.item())\n",
        "\n",
        "      if next_token.item() == tokenizer.eos_token_id:\n",
        "          break\n",
        "      print(decoder_input)\n",
        "      decoder_input = torch.cat([decoder_input, next_token.unsqueeze(0)], dim=1)\n",
        "      print(decoder_input)\n",
        "    translated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "  return translated_text\n"
      ],
      "metadata": {
        "id": "chKWkv56DJNT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### print(\"\\nStep by step generation:\")\n",
        "# for i in range(len(generated_tokens)):\n",
        "#     partial_text = tokenizer.decode(generated_tokens[:i+1], skip_special_tokens=True)\n",
        "#     print(f\"Step {i+1}: {partial_text}\")"
      ],
      "metadata": {
        "id": "AVfheO9c8MM3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.num_beams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kypz225xV07O",
        "outputId": "d41bfbc1-d5df-492e-93f2-073d22660a59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_translation(ds['validation'][1]['translation']['tr']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUR-FySHjfHZ",
        "outputId": "409e6e8e-c720-43fc-82d8-e6cd80076b00",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[62388]])\n",
            "tensor([[62388, 31058]])\n",
            "tensor([[62388, 31058]])\n",
            "tensor([[62388, 31058,     4]])\n",
            "tensor([[62388, 31058,     4]])\n",
            "tensor([[62388, 31058,     4,     8]])\n",
            "tensor([[62388, 31058,     4,     8]])\n",
            "tensor([[62388, 31058,     4,     8,  1129]])\n",
            "tensor([[62388, 31058,     4,     8,  1129]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101,    21]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101,    21]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101,    21,\n",
            "             9]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101,    21,\n",
            "             9]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101,    21,\n",
            "             9,   476]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101,    21,\n",
            "             9,   476]])\n",
            "tensor([[62388, 31058,     4,     8,  1129,  1782,   206,  3094,     9, 11363,\n",
            "          1444, 13521,     3,    39,    66,    21,  4793,     3,   101,    21,\n",
            "             9,   476,     2]])\n",
            "Norway's five million people enjoy the highest living standards, not just in Europe, but in the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"validation\"][1][\"translation\"][\"tr\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ld36ZcknI28I",
        "outputId": "2fd4e632-7879-4c0f-aac2-21fadeaf1357"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Norveç'in beş milyon insanı en yüksek yaşam standartlarının tadını çıkarıyor, sadece Avrupa'da değil, dünyada.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"validation\"][1][\"translation\"][\"en\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "2qleapnBJH_O",
        "outputId": "1926da39-8297-4580-9b00-f3fcaf7e1478"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Norway's five million people enjoy one of the highest standards of living, not just in Europe, but in the world.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reference to get the python file from github\n",
        "\n"
      ],
      "metadata": {
        "id": "QEX8b_r7JIox"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/jckantor/cbe61622/blob/master/docs/A.02-Downloading_Python_source_files_from_github.ipynb"
      ],
      "metadata": {
        "id": "nEY02UDwk3p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get constraints\n",
        "\n",
        "user = \"vvikasreddy\"\n",
        "repo = \"lexically_constrained_beam_search_\"\n",
        "pyfile = \"constraints.py\"\n",
        "\n",
        "# url = \"https://github.com/vvikasreddy/lexically_constrained_beam_search_/blob/main/constraints.py\"\n",
        "url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{pyfile}\"\n",
        "!wget --no-cache --backups=1 {url}\n",
        "\n",
        "import constraints"
      ],
      "metadata": {
        "id": "jrClS2MolMXW",
        "collapsed": true,
        "outputId": "20a9af74-0bab-4558-fe79-c6f4da0f25b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-04 22:08:59--  https://raw.githubusercontent.com/vvikasreddy/lexically_constrained_beam_search_/main/constraints.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4406 (4.3K) [text/plain]\n",
            "Saving to: ‘constraints.py’\n",
            "\n",
            "constraints.py      100%[===================>]   4.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-04 22:08:59 (34.1 MB/s) - ‘constraints.py’ saved [4406/4406]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes nice 5 minutes to get all the constraints of length 2\n",
        "c = constraints.get_constraints()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L9LeDVKbZlK1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_translation(src_text, decoder_input = [], probabilites = [],  max_length = 1, get_constrained_token_probability = -1):\n",
        "\n",
        "  \"\"\"generate the decoder input ids and corresponding probabilities\"\"\"\n",
        "\n",
        "\n",
        "  # Tokenize input\n",
        "  encoder_inputs = tokenizer(src_text, return_tensors=\"pt\")\n",
        "\n",
        "  # initialize if not initialized.\n",
        "  if decoder_input == []:\n",
        "    # because the intial decoder start token has probabilitty 1\n",
        "    probabilites = torch.tensor([[1]])\n",
        "    decoder_input = torch.tensor([[model.config.decoder_start_token_id]])\n",
        "\n",
        "  # change the model to eval mode.\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    generated_tokens = []\n",
        "\n",
        "    outputs = model(\n",
        "        input_ids=encoder_inputs.input_ids,\n",
        "        attention_mask=encoder_inputs.attention_mask,\n",
        "        decoder_input_ids=decoder_input\n",
        "    )\n",
        "\n",
        "    next_token_logits = outputs.logits[:, -1, :]\n",
        "\n",
        "    if get_constrained_token_probability != -1:\n",
        "      # print(next_token_logits.shape)\n",
        "      softmax_  = torch.softmax(next_token_logits, dim=-1)\n",
        "      return softmax_[0][get_constrained_token_probability]\n",
        "\n",
        "    # get the token with maximum logits value\n",
        "\n",
        "    next_token = torch.argmax(next_token_logits, dim=-1)\n",
        "\n",
        "\n",
        "    top_probs, top_indices = torch.topk(torch.softmax(next_token_logits, dim=-1), k = 5)\n",
        "\n",
        "\n",
        "  decoder_inputs = []\n",
        "  probs = []\n",
        "  # to visualize data\n",
        "  vis_data = []\n",
        "  for indx, id in enumerate(top_indices[0]):\n",
        "    # print(decoder_input, id.unsqueeze(0).unsqueeze(0), id, \"jhere\")\n",
        "    # print(probabilities, top_probs[0][indx].unsqueeze(0).unsqueeze(0))\n",
        "    decoder_inputs.append(torch.cat([decoder_input, id.unsqueeze(0).unsqueeze(0)], dim=1))\n",
        "    probs.append(torch.cat([probabilites, top_probs[0][indx].unsqueeze(0).unsqueeze(0)], dim=1))\n",
        "    # print(decoder_inputs[indx], indx)\n",
        "    vis_data.append((vis_data, tokenizer.decode(decoder_inputs[indx].squeeze(), skip_special_tokens = True)))\n",
        "  # translated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "  # print(decoder_inputs, probs)\n",
        "  # print(vis_data)9\n",
        "  return decoder_inputs, probs, vis_data\n",
        "  # return decoder_input, probabilities\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Lb1AIoB-akSu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXRy51xPXsYe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_translation(ds['validation'][1]['translation']['tr'], decoder_input = torch.tensor([[62388,  1969]]), probabilites = torch.tensor([[0.0000, 0.0000]])))\n",
        "# c"
      ],
      "metadata": {
        "id": "6sHR_gr1pUy1",
        "outputId": "331a15c6-7e05-433f-b130-8fc6c6cd0000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([tensor([[62388,  1969,   261]]), tensor([[62388,  1969,    15]]), tensor([[62388,  1969,   510]]), tensor([[62388,  1969,     8]]), tensor([[62388,  1969,    47]])], [tensor([[0.0000, 0.0000, 0.3950]]), tensor([[0.0000, 0.0000, 0.1113]]), tensor([[0.0000, 0.0000, 0.0247]]), tensor([[0.0000, 0.0000, 0.0110]]), tensor([[0.0000, 0.0000, 0.0105]])], [([...], 'Koso'), ([...], 'Kost'), ([...], 'Kosum'), ([...], 'Koss'), ([...], 'Kosa')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ngrams(src, n = 2, ):\n",
        "  src = src.split(\" \")\n",
        "\n",
        "  src = [tuple(src[i:i+n]) for i in range(len(src) - n + 1)]\n",
        "\n",
        "  return src\n",
        "\n",
        "def constraints_tokens(src, c):\n",
        "  ngrams = get_ngrams(src)\n",
        "  constraints_src = []\n",
        "  for ngram in ngrams:\n",
        "    # print(ngram)\n",
        "    if ngram in c:\n",
        "      for gram in ngram:\n",
        "\n",
        "        constraints_src.append(tokenizer(gram, return_tensors=\"pt\"))\n",
        "  return constraints_src\n",
        "\n",
        "def get_input_ids(data):\n",
        "\n",
        "  input_ids = []\n",
        "  for example in data:\n",
        "    input_ids.append((example['input_ids'][0].tolist())[0])\n",
        "  return input_ids"
      ],
      "metadata": {
        "id": "m31ZnR46R1S0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = constraints_tokens(ds['validation'][1]['translation']['tr'] + ' Times' +  ' için', c)\n",
        "# c\n",
        "print(x)\n",
        "print(get_input_ids(x))"
      ],
      "metadata": {
        "id": "YAE_CMBYSeHr",
        "outputId": "d28c1e8f-1cb1-4be9-d928-f19a8d238735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'input_ids': tensor([[3762,    0]]), 'attention_mask': tensor([[1, 1]])}, {'input_ids': tensor([[37,  0]]), 'attention_mask': tensor([[1, 1]])}]\n",
            "[3762, 37]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_data(decoder_input):\n",
        "  return tokenizer.decode(decoder_input.squeeze(), skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "ecRWZg9IDyQl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_top_k_prob(A, B, k=2):\n",
        "\n",
        "  d = {}\n",
        "  # cummulative sum\n",
        "  for indx, val in enumerate(B):\n",
        "\n",
        "    cum_sum = torch.prod(val)\n",
        "    d[cum_sum] = indx\n",
        "\n",
        "  sorted_keys = sorted(d.keys(), reverse = True)\n",
        "\n",
        "  top_k_indices = []\n",
        "  top_k_sequences = []\n",
        "\n",
        "  for key in sorted_keys[:k]:\n",
        "    top_k_indices.append(A[d[key]])\n",
        "    top_k_sequences.append(B[d[key]])\n",
        "\n",
        "  return top_k_sequences, top_k_indices\n",
        "\n",
        "# sanity\n",
        "k = 2\n",
        "\n",
        "A = [torch.tensor([[62388,   626,    13]]), torch.tensor([[62388,   626,     9]]), torch.tensor([[62388,   626,  1341]]), torch.tensor([[62388,   626,    27]])]\n",
        "B = [torch.tensor([[1.0000, 0.0038, 0.2500]]), torch.tensor([[1.0000, 0.0038, 0.0619]]), torch.tensor([[1.0000, 0.0038, 0.0474]]), torch.tensor([[1.0000, 0.0038, 0.0425]])]\n",
        "\n",
        "top_sequences, indices = get_top_k_prob(A, B, k)\n",
        "print(f\"Top {k} sequences:\", top_sequences)\n",
        "print(\"Their indices:\", indices)"
      ],
      "metadata": {
        "id": "nGCXp6x4OEj2",
        "outputId": "87e97735-1eb1-4558-c9e8-4deef919c376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 2 sequences: [tensor([[1.0000, 0.0038, 0.2500]]), tensor([[1.0000, 0.0038, 0.0619]])]\n",
            "Their indices: [tensor([[62388,   626,    13]]), tensor([[62388,   626,     9]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(maxlen, numC, k, src, constraints):\n",
        "\n",
        "    decoder_start_token = model.config.decoder_start_token_id\n",
        "\n",
        "    # initialize the grids\n",
        "    grids = [[[] for _ in range(numC + 1)] for _ in range(maxlen + 1)]\n",
        "    probs_grid  = [[[] for _ in range(numC + 1)] for _ in range(maxlen + 1)]\n",
        "\n",
        "    # intialize the first grid to start hyp\n",
        "    grids[0][0] = [1]\n",
        "\n",
        "\n",
        "    # remove during testsrc\n",
        "    # constrained_tokens = get_input_ids(constraints_tokens(, constraints))\n",
        "    # temporary\n",
        "    constrained_tokens = [3762, 37]\n",
        "\n",
        "    generated_constraint_index = 0\n",
        "\n",
        "    for t in range(1, maxlen):\n",
        "\n",
        "      index_c = max(0, (numC - t) - maxlen)\n",
        "\n",
        "      for c in range(index_c, min(t, numC) + 1):\n",
        "\n",
        "\n",
        "          print(\"cur iteration \", t, c )\n",
        "          s = []\n",
        "          g = []\n",
        "\n",
        "          # storing decoder inputs\n",
        "          decoder_inputs = []\n",
        "          probs = []\n",
        "\n",
        "          # print(grids)\n",
        "          # print(probs_grid[t-1][c], \"hey yo \", t - 1, c)\n",
        "          for indx, element in enumerate(grids[t-1][c]):\n",
        "\n",
        "            # guess there is no need for conditioning, just generate.\n",
        "            # print(element, \"this is the element\")\n",
        "            if type(element) == int:\n",
        "              decoder_input = []\n",
        "              probs =[]\n",
        "            else:\n",
        "              decoder_input = element\n",
        "              probs = probs_grid[t-1][c][indx]\n",
        "\n",
        "            # print(element)\n",
        "            # print(decoder_input)\n",
        "            # print(probs)\n",
        "            # print(\"----------------------------\")\n",
        "            g, probs, vis_data = generate_translation(src_text= src, decoder_input = decoder_input, probabilites = probs)\n",
        "\n",
        "\n",
        "          # retrieve the  probability of the constraint and add that to the decoder_input.\n",
        "          if c > 0 and constrained_tokens:\n",
        "\n",
        "            for indx, element in enumerate(grids[t-1][c-1]):\n",
        "\n",
        "              if c == 1 and t == 1:\n",
        "                decoder_inputs = torch.tensor([[model.config.decoder_start_token_id]])\n",
        "                prob = torch.tensor([[1]])\n",
        "\n",
        "              else:\n",
        "                decoder_inputs = element\n",
        "                prob = probs_grid[t-1][c-1][indx]\n",
        "\n",
        "              # Gets the constraints probability and stores them\n",
        "              cons = generate_translation(src, decoder_input = decoder_input, get_constrained_token_probability = constrained_tokens[c - 1])\n",
        "              # print(cons, decoder_inputs, element)\n",
        "              decoder_inputs = torch.cat([decoder_inputs, torch.tensor(constrained_tokens[c-1]).unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "              prob = torch.cat([prob, torch.tensor(cons).unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "\n",
        "\n",
        "              g.append(decoder_inputs)\n",
        "\n",
        "              probs.append(prob)\n",
        "\n",
        "          probs_grid[t][c], grids[t][c] = get_top_k_prob(g, probs, k)\n",
        "\n",
        "          # print(grids[t][c], t, c )\n",
        "          # print(probs_grid[t][c])\n",
        "          for i in  grids[t][c]:\n",
        "            print(visualize_data(i), i )\n",
        "\n",
        "\n",
        "          print('asd-------------------------------------------')\n",
        "\n",
        "  # sanity : print grids\n",
        "    print(grids)\n",
        "\n",
        "\n",
        "beam_search(maxlen= 10, numC=2, k = 2, src = ds[\"train\"][1][\"translation\"][\"tr\"], constraints = c)"
      ],
      "metadata": {
        "id": "rp4JV4xqay72",
        "outputId": "bca10d95-818e-4a13-8c2d-eb6b53c060ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cur iteration  1 0\n",
            "Kos tensor([[62388,  1969]])\n",
            "In tensor([[62388,   323]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  1 1\n",
            "Times tensor([[62388,  3762]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  2 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-1d3a7f9c3eb3>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  prob = torch.cat([prob, torch.tensor(cons).unsqueeze(0).unsqueeze(0)], dim=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In light tensor([[62388,   323,  1341]])\n",
            "In view tensor([[62388,   323,  4316]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  2 1\n",
            "Kos Times tensor([[62388,  1969,  3762]])\n",
            "In Times tensor([[62388,   323,  3762]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  2 2\n",
            "Times için tensor([[62388,  3762,    37]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  3 0\n",
            "In view of tensor([[62388,   323,  4316,    16]])\n",
            "In view to tensor([[62388,   323,  4316,    11]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  3 1\n",
            "In light Times tensor([[62388,   323,  1341,  3762]])\n",
            "In view Times tensor([[62388,   323,  4316,  3762]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  3 2\n",
            "Kos Times için tensor([[62388,  1969,  3762,    37]])\n",
            "In Times için tensor([[62388,   323,  3762,    37]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  4 0\n",
            "In view to repeated tensor([[62388,   323,  4316,    11, 31187]])\n",
            "In view to the tensor([[62388,   323,  4316,    11,     9]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  4 1\n",
            "In view of Times tensor([[62388,   323,  4316,    16,  3762]])\n",
            "In view Times of tensor([[62388,   323,  4316,  3762,    16]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  4 2\n",
            "In light Times için tensor([[62388,   323,  1341,  3762,    37]])\n",
            "In Times için, tensor([[62388,   323,  3762,    37,     3]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  5 0\n",
            "In view to the repeated tensor([[62388,   323,  4316,    11,     9, 31187]])\n",
            "In view to the recurring tensor([[62388,   323,  4316,    11,     9, 51075]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  5 1\n",
            "In view Times of repeated tensor([[62388,   323,  4316,  3762,    16, 31187]])\n",
            "In view Times of rep tensor([[62388,   323,  4316,  3762,    16, 16635]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  5 2\n",
            "In Times için, Kos tensor([[62388,   323,  3762,    37,     3,  1969]])\n",
            "In view of Times için tensor([[62388,   323,  4316,    16,  3762,    37]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  6 0\n",
            "In view to the recurring complaints tensor([[62388,   323,  4316,    11,     9, 51075, 25899]])\n",
            "In view to the recurring complaint tensor([[62388,   323,  4316,    11,     9, 51075, 18442]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  6 1\n",
            "In view Times of repeti tensor([[62388,   323,  4316,  3762,    16, 16635, 10655]])\n",
            "In view Times of reprod tensor([[62388,   323,  4316,  3762,    16, 16635, 13816]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  6 2\n",
            "In view Times of repeated için tensor([[62388,   323,  4316,  3762,    16, 31187,    37]])\n",
            "In view of Times için, tensor([[62388,   323,  4316,    16,  3762,    37,     3]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  7 0\n",
            "In view to the recurring complaint, tensor([[62388,   323,  4316,    11,     9, 51075, 18442,     3]])\n",
            "In view to the recurring complaint Kos tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  7 1\n",
            "In view Times of reproduc tensor([[62388,   323,  4316,  3762,    16, 16635, 13816, 18327]])\n",
            "In view Times of reprodul tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  7 2\n",
            "In view of Times için, Kos tensor([[62388,   323,  4316,    16,  3762,    37,     3,  1969]])\n",
            "In view Times of repeti için tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  8 0\n",
            "In view to the recurring complaint Koso tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,   261]])\n",
            "In view to the recurring complaint Kosova tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,  2922]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  8 1\n",
            "In view Times of reproduls tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,     8]])\n",
            "In view Times of reproduling tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,   132]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  8 2\n",
            "In view Times of repeti içinre tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,    33]])\n",
            "In view Times of repeti içinring tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,  6073]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  9 0\n",
            "In view to the recurring complaint Kosova is tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,  2922,    23]])\n",
            "In view to the recurring complaint Kosova has tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,  2922,   168]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  9 1\n",
            "In view Times of reproduling complaints tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,   132, 25899]])\n",
            "In view Times of reproduling complaint tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,   132, 18442]])\n",
            "asd-------------------------------------------\n",
            "cur iteration  9 2\n",
            "In view Times of repeti içinring complaints tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,  6073, 25899]])\n",
            "In view Times of repeti içinring complaint tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,  6073, 18442]])\n",
            "asd-------------------------------------------\n",
            "[[[1], [], []], [[tensor([[62388,  1969]]), tensor([[62388,   323]])], [tensor([[62388,  3762]])], []], [[tensor([[62388,   323,  1341]]), tensor([[62388,   323,  4316]])], [tensor([[62388,  1969,  3762]]), tensor([[62388,   323,  3762]])], [tensor([[62388,  3762,    37]])]], [[tensor([[62388,   323,  4316,    16]]), tensor([[62388,   323,  4316,    11]])], [tensor([[62388,   323,  1341,  3762]]), tensor([[62388,   323,  4316,  3762]])], [tensor([[62388,  1969,  3762,    37]]), tensor([[62388,   323,  3762,    37]])]], [[tensor([[62388,   323,  4316,    11, 31187]]), tensor([[62388,   323,  4316,    11,     9]])], [tensor([[62388,   323,  4316,    16,  3762]]), tensor([[62388,   323,  4316,  3762,    16]])], [tensor([[62388,   323,  1341,  3762,    37]]), tensor([[62388,   323,  3762,    37,     3]])]], [[tensor([[62388,   323,  4316,    11,     9, 31187]]), tensor([[62388,   323,  4316,    11,     9, 51075]])], [tensor([[62388,   323,  4316,  3762,    16, 31187]]), tensor([[62388,   323,  4316,  3762,    16, 16635]])], [tensor([[62388,   323,  3762,    37,     3,  1969]]), tensor([[62388,   323,  4316,    16,  3762,    37]])]], [[tensor([[62388,   323,  4316,    11,     9, 51075, 25899]]), tensor([[62388,   323,  4316,    11,     9, 51075, 18442]])], [tensor([[62388,   323,  4316,  3762,    16, 16635, 10655]]), tensor([[62388,   323,  4316,  3762,    16, 16635, 13816]])], [tensor([[62388,   323,  4316,  3762,    16, 31187,    37]]), tensor([[62388,   323,  4316,    16,  3762,    37,     3]])]], [[tensor([[62388,   323,  4316,    11,     9, 51075, 18442,     3]]), tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969]])], [tensor([[62388,   323,  4316,  3762,    16, 16635, 13816, 18327]]), tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304]])], [tensor([[62388,   323,  4316,    16,  3762,    37,     3,  1969]]), tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37]])]], [[tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,   261]]), tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,  2922]])], [tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,     8]]), tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,   132]])], [tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,    33]]), tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,  6073]])]], [[tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,  2922,    23]]), tensor([[62388,   323,  4316,    11,     9, 51075, 18442,  1969,  2922,   168]])], [tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,   132, 25899]]), tensor([[62388,   323,  4316,  3762,    16, 16635, 13816,  1304,   132, 18442]])], [tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,  6073, 25899]]), tensor([[62388,   323,  4316,  3762,    16, 16635, 10655,    37,  6073, 18442]])]], [[], [], []]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ihW0o7aR_Xt_"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}